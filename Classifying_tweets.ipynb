{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vogrCA5aYPtQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import sklearn\n",
        "import string\n",
        "import re # helps you filter urls\n",
        "from IPython.display import display, Latex, Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GSK7qFiMfMM",
        "outputId": "cf2eaa36-3c8e-4302-d89f-fc7b0542a182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PmFK0GgYPtU"
      },
      "source": [
        "# Classifying tweets\n",
        "\n",
        "Analyzing Twitter data related to the 2016 US Presidential election extracted using [the Twitter API](https://dev.twitter.com/overview/api). The data contains tweets posted by the following six Twitter accounts: `realDonaldTrump, mike_pence, GOP, HillaryClinton, timkaine, TheDemocrats`\n",
        "\n",
        "For every tweet, there are two pieces of information:\n",
        "- `screen_name`: the Twitter handle of the user tweeting and\n",
        "- `text`: the content of the tweet.\n",
        "\n",
        "\n",
        " Overarching goal of is to \"predict\" the political inclination (Republican/Democratic) of the Twitter user from one of his/her tweets. The ground truth (i.e., true class labels) is determined from the `screen_name` of the tweet as follows\n",
        "- `realDonaldTrump, mike_pence, GOP` are Republicans\n",
        "- `HillaryClinton, timkaine, TheDemocrats` are Democrats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wQGjuhliYPtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f7df64-0aea-4181-f41a-dc0b1063fbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
        "stopwords=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTqEaBw9YPtZ"
      },
      "source": [
        "\n",
        "## Text Processing\n",
        "\n",
        "The function  processes and tokenizes raw text. The generated list of tokens  meets the following specifications:\n",
        "1. The tokens are in lower case.\n",
        "2. The tokens appear in the same order as in the raw text.\n",
        "3. The tokens are in their lemmatized form.\n",
        "4. The tokens does not contain any punctuations.\n",
        "5. The tokens do not contain any part of a url.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2yXsTPLPECF",
        "outputId": "f9173168-bc81-4db5-ea42-afd91eb5f8e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B5IMtsQoYPta"
      },
      "outputs": [],
      "source": [
        "# Converting part of speech tag from nltk.pos_tag to word net compatible format\n",
        "# Simple mapping based on first letter of return tag to make grading consistent\n",
        "# Everything else is considered noun 'n'\n",
        "posMapping = {\n",
        "# \"First_Letter by nltk.pos_tag\":\"POS_for_lemmatizer\"\n",
        "    \"N\":'n',\n",
        "    \"V\":'v',\n",
        "    \"J\":'a',\n",
        "    \"R\":'r'\n",
        "}\n",
        "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
        "    \"\"\" Normalizes case and handles punctuation\n",
        "    Inputs:\n",
        "        text: str: raw text\n",
        "        lemmatizer: an instance of a class implementing the lemmatize() method\n",
        "                    (the default argument is of type nltk.stem.wordnet.WordNetLemmatizer)\n",
        "    Outputs:\n",
        "        list(str): tokenized text\n",
        "    \"\"\"\n",
        "    regex=r'http[s]?://\\S+|www\\.\\S+'\n",
        "    text=re.sub(regex,'',text)\n",
        "    text=text.lower()\n",
        "\n",
        "    text = re.sub(r\"'s\\b\", '', text)\n",
        "    text = re.sub(r\"'\", '', text)\n",
        "    regex2 = r'[!\"#$%&\\'()*+,\\-./:;<=>?@[\\\\\\]^_`{|}~]'\n",
        "    text = re.sub(regex2, ' ', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tags = nltk.pos_tag(tokens)\n",
        "\n",
        "\n",
        "    lemma = []\n",
        "\n",
        "    for word, pos_tg in tags:\n",
        "      pos_char = pos_tg[0]\n",
        "      pos_mapped = posMapping.get(pos_char, 'n')\n",
        "\n",
        "      try:\n",
        "          lemma_word = lemmatizer.lemmatize(word, pos=pos_mapped)\n",
        "          lemma.append(lemma_word)\n",
        "      except Exception as e:\n",
        "          continue\n",
        "\n",
        "\n",
        "    return lemma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtCxYV3pDf5A",
        "outputId": "1213a2d6-1db4-4b83-9d4d-f45ca40cdde0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')  # Correct tagger resource\n",
        "nltk.download('punkt')  # For tokenization\n",
        "nltk.download('wordnet')  # For lemmatization\n",
        "nltk.download('stopwords')  # For stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv8qREyTDumD",
        "outputId": "c4314659-a461-4764-ddde-b1e85563adbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq33we_xEO_r",
        "outputId": "610330b8-3af1-49f8-bded-f789d12dbda9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UrEzaolBYPtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feec243a-dc98-42d6-d36f-890d10787c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['im', 'do', 'well', 'how', 'about', 'you']\n",
            "['education', 'be', 'the', 'ability', 'to', 'listen', 'to', 'almost', 'anything', 'without', 'lose', 'your', 'temper', 'or', 'your', 'self', 'confidence']\n",
            "['be', 'have', 'do', 'language', 'city', 'mice']\n",
            "['it', 'hilarious', 'check', 'it', 'out']\n",
            "['see', 'it', 'sunday', 'morning', 'at', '8', '30a', 'on', 'rtv6', 'and', 'our', 'rtv6', 'app', 'http', '…']\n"
          ]
        }
      ],
      "source": [
        "print(process(\"I'm doing well! How about you?\"))\n",
        "# ['im', 'do', 'well', 'how', 'about', 'you']\n",
        "\n",
        "print(process(\"Education is the ability to listen to almost anything without losing your temper or your self-confidence.\"))\n",
        "# ['education', 'be', 'the', 'ability', 'to', 'listen', 'to', 'almost', 'anything', 'without', 'lose', 'your', 'temper', 'or', 'your', 'self', 'confidence']\n",
        "\n",
        "print(process(\"been had done languages cities mice\"))\n",
        "# ['be', 'have', 'do', 'language', 'city', 'mice']\n",
        "\n",
        "print(process(\"It's hilarious. Check it out http://t.co/dummyurl\"))\n",
        "# ['it', 'hilarious', 'check', 'it', 'out']\n",
        "\n",
        "print(process(\"See it Sunday morning at 8:30a on RTV6 and our RTV6 app. http:…\"))\n",
        "# ['see', 'it', 'sunday', 'morning', 'at', '8', '30a', 'on', 'rtv6', 'and', 'our', 'rtv6', 'app', 'http', '…']\n",
        "# Here '…' is a special unicode character not in string.punctuation and it is still present in processed text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "aEONT9fXYPti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "29920d98-058f-4dbd-f727-842737de9cd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      screen_name                                               text\n",
              "0             GOP  RT @GOPconvention: #Oregon votes today. That m...\n",
              "1    TheDemocrats  RT @DWStweets: The choice for 2016 is clear: W...\n",
              "2  HillaryClinton  Trump's calling for trillion dollar tax cuts f...\n",
              "3  HillaryClinton  .@TimKaine's guiding principle: the belief tha...\n",
              "4        timkaine  Glad the Senate could pass a #THUD / MilCon / ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23df88a5-ee09-416e-9396-e3ced1fe32ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GOP</td>\n",
              "      <td>RT @GOPconvention: #Oregon votes today. That m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TheDemocrats</td>\n",
              "      <td>RT @DWStweets: The choice for 2016 is clear: W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HillaryClinton</td>\n",
              "      <td>Trump's calling for trillion dollar tax cuts f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HillaryClinton</td>\n",
              "      <td>.@TimKaine's guiding principle: the belief tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>timkaine</td>\n",
              "      <td>Glad the Senate could pass a #THUD / MilCon / ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23df88a5-ee09-416e-9396-e3ced1fe32ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23df88a5-ee09-416e-9396-e3ced1fe32ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23df88a5-ee09-416e-9396-e3ced1fe32ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-354910a4-9475-4293-844d-29a7b3222868\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-354910a4-9475-4293-844d-29a7b3222868')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-354910a4-9475-4293-844d-29a7b3222868 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(tweets\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"screen_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"TheDemocrats\",\n          \"timkaine\",\n          \"GOP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RT @DWStweets: The choice for 2016 is clear: We need another Democrat in the White House. #DemDebate #WeAreDemocrats http://t.co/0n5g0YN46f\",\n          \"Glad the Senate could pass a #THUD / MilCon / VetAffairs approps bill with solid provisions for Virginia: https://t.co/NxIgRC3hDi\",\n          \"Trump's calling for trillion dollar tax cuts for Wall Street.\\n\\nIt's time for them to pay their fair share. https://t.co/y8vyESIOES\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tweets = pd.read_csv(\"/content/tweets_train.csv\", na_filter=False)\n",
        "display(tweets.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SM7hJBdOYPtl"
      },
      "outputs": [],
      "source": [
        "def process_all(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
        "    \"\"\" process all text in the dataframe using process() function.\n",
        "    Inputs\n",
        "        df: pd.DataFrame: dataframe containing a column 'text' loaded from the CSV file\n",
        "        lemmatizer: an instance of a class implementing the lemmatize() method\n",
        "                    (the default argument is of type nltk.stem.wordnet.WordNetLemmatizer)\n",
        "    Outputs\n",
        "        pd.DataFrame: dataframe in which the values of text column have been changed from str to list(str),\n",
        "                        the output from process() function. Other columns are unaffected.\n",
        "    \"\"\"\n",
        "    df['text'] = df['text'].apply(process)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lXQP6CAiYPto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5801951-2242-43b4-a08c-fff9aa17727c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      screen_name                                               text\n",
            "0             GOP  [rt, gopconvention, oregon, vote, today, that,...\n",
            "1    TheDemocrats  [rt, dwstweets, the, choice, for, 2016, be, cl...\n",
            "2  HillaryClinton  [trump, call, for, trillion, dollar, tax, cut,...\n",
            "3  HillaryClinton  [timkaine, guide, principle, the, belief, that...\n",
            "4        timkaine  [glad, the, senate, could, pass, a, thud, milc...\n"
          ]
        }
      ],
      "source": [
        "processed_tweets = process_all(tweets)\n",
        "print(processed_tweets.head())\n",
        "\n",
        "#       screen_name                                               text\n",
        "# 0             GOP  [rt, gopconvention, oregon, vote, today, that,...\n",
        "# 1    TheDemocrats  [rt, dwstweets, the, choice, for, 2016, be, cl...\n",
        "# 2  HillaryClinton  [trump, call, for, trillion, dollar, tax, cut,...\n",
        "# 3  HillaryClinton  [timkaine, guide, principle, the, belief, that...\n",
        "# 4        timkaine  [glad, the, senate, could, pass, a, thud, milc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsBiunCIYPtr"
      },
      "source": [
        "## B. Feature Construction\n",
        "\n",
        "This step is to derive feature vectors from the tokenized tweets. In this section, we are  constructing a bag-of-words TF-IDF feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8NQ9wVm3YPt0"
      },
      "outputs": [],
      "source": [
        "def create_features(processed_tweets, stop_words):\n",
        "    \"\"\" creates the feature matrix using the processed tweet text\n",
        "    Inputs:\n",
        "        processed_tweets: pd.DataFrame: processed tweets read from train/test csv file, containing the column 'text'\n",
        "        stop_words: list(str): stop_words by nltk stopwords (after processing)\n",
        "    Outputs:\n",
        "        sklearn.feature_extraction.text.TfidfVectorizer: the TfidfVectorizer object used\n",
        "            we need this to tranform test tweets in the same way as train tweets\n",
        "        scipy.sparse.csr.csr_matrix: sparse bag-of-words TF-IDF feature matrix\n",
        "    \"\"\"\n",
        "\n",
        "    lis_stop_words=list(stop_words)\n",
        "\n",
        "    tfidf_vector = sklearn.feature_extraction.text.TfidfVectorizer(\n",
        "        stop_words=lis_stop_words,\n",
        "        min_df=2,\n",
        "        analyzer='word'\n",
        "    )\n",
        "\n",
        "    string_tweets = [\" \".join(tokens) for tokens in processed_tweets['text']]\n",
        "    mat = tfidf_vector.fit_transform(string_tweets)\n",
        "    return tfidf_vector, mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XXYtqEyvYPt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35adfa06-e706-4457-fc51-18a16199e0eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TfidfVectorizer(min_df=2,\n",
              "                 stop_words=['other', 'be', 'itself', 'wouldn', 'm', 'an',\n",
              "                             'hasn', 'but', 'such', 'shouldve', 'youll', 'youd',\n",
              "                             'yourself', 'any', 'about', 'by', 'between', 'too',\n",
              "                             'against', 'youre', 'she', 'wasn', 'down', 'ma',\n",
              "                             'the', 'to', 'when', 'i', 'haven', 'ourselves', ...]),\n",
              " <17298x7915 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 161708 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "processed_stopwords = set(np.concatenate([process(word) for word in stopwords]))\n",
        "(tfidf, X) = create_features(processed_tweets, processed_stopwords)\n",
        "# Ignore warning\n",
        "tfidf, X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQJih7SYPt6"
      },
      "source": [
        "\n",
        "\n",
        "For each tweet, assigning a class label (0 or 1) using its `screen_name`. using 0 for realDonaldTrump, mike_pence, GOP and 1 for the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bLtDPaInYPt7"
      },
      "outputs": [],
      "source": [
        "def create_labels(processed_tweets):\n",
        "    \"\"\" creates the class labels from screen_name\n",
        "    Inputs:\n",
        "        processed_tweets: pd.DataFrame: tweets read from train file, containing the column 'screen_name'\n",
        "    Outputs:\n",
        "        numpy.ndarray(int): dense binary numpy array of class labels\n",
        "    \"\"\"\n",
        "    Republicans = {'realDonaldTrump', 'mike_pence', 'GOP'}\n",
        "\n",
        "    class_labels_screen_name = processed_tweets['screen_name'].apply(lambda x: 0 if x in Republicans else 1)\n",
        "\n",
        "    return class_labels_screen_name.to_numpy(dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "z49a4djKYPt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9f706c-827c-4d4c-f2b0-f8f966dc0f33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 1, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y = create_labels(processed_tweets)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5STbtJYSYPuA"
      },
      "source": [
        "## Classification\n",
        "Integrating things together and implementing a model for the classification of tweets.\n",
        "\n",
        "\n",
        "To determine whether  classifier is performing well, comparing it to a baseline classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xUBpZ6_NYPuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae32c3fd-2c24-4d04-e793-484c16c71632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5001734304543878\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class MajorityLabelClassifier():\n",
        "    \"\"\"\n",
        "    A classifier that predicts the mode of training labels\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize your parameter here\n",
        "        \"\"\"\n",
        "        self.most_frequent_class = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Implement fit by taking training data X and their labels y and finding the mode of y\n",
        "        i.e. store your learned parameter\n",
        "        \"\"\"\n",
        "        self.most_frequent_class = np.argmax(np.bincount(y))\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Implement to give the mode of training labels as a prediction for each data instance in X\n",
        "        return labels\n",
        "        \"\"\"\n",
        "        return [self.most_frequent_class for _ in range(X.shape[0])]\n",
        "\n",
        "baselineClf = MajorityLabelClassifier()\n",
        "\n",
        "baselineClf.fit(X, y)\n",
        "y_pred = baselineClf.predict(X)\n",
        "training_accuracy = sklearn.metrics.accuracy_score(y, y_pred)\n",
        "print(training_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZldwD1JYPuD"
      },
      "source": [
        "Implementing the `learn_classifier()` function  `kernel` is always one of {`linear`, `poly`, `rbf`, `sigmoid`}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WGpfOK2EYPuD"
      },
      "outputs": [],
      "source": [
        "def learn_classifier(X_train, y_train, kernel):\n",
        "    \"\"\" learns a classifier from the input features and labels using the kernel function supplied\n",
        "    Inputs:\n",
        "        X_train: scipy.sparse.csr.csr_matrix: sparse matrix of features, output of create_features()\n",
        "        y_train: numpy.ndarray(int): dense binary vector of class labels, output of create_labels()\n",
        "        kernel: str: kernel function to be used with classifier. [linear|poly|rbf|sigmoid]\n",
        "    Outputs:\n",
        "        sklearn.svm.SVC: classifier learnt from data\n",
        "    \"\"\"\n",
        "\n",
        "    svm_classifier=sklearn.svm.SVC(kernel=kernel)\n",
        "    svm_classifier.fit(X_train, y_train)\n",
        "    return svm_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "iOwIKVuvYPuF"
      },
      "outputs": [],
      "source": [
        "\n",
        "classifier = learn_classifier(X, y, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tvLsjxqKYPuL"
      },
      "outputs": [],
      "source": [
        "def evaluate_classifier(classifier, X_validation, y_validation):\n",
        "    \"\"\" evaluates a classifier based on a supplied validation data\n",
        "    Inputs:\n",
        "        classifier: sklearn.svm.classes.SVC: classifer to evaluate\n",
        "        X_validation: scipy.sparse.csr.csr_matrix: sparse matrix of features\n",
        "        y_validation: numpy.ndarray(int): dense binary vector of class labels\n",
        "    Outputs:\n",
        "        double: accuracy of classifier on the validation data\n",
        "    \"\"\"\n",
        "    y_pred_val = classifier.predict(X_validation)\n",
        "    val_accuracy=sklearn.metrics.accuracy_score(y_validation,y_pred_val)\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "pmdMkFIzYPuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa335213-5128-474e-fbe6-922117664ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9512660423170308\n"
          ]
        }
      ],
      "source": [
        "accuracy = evaluate_classifier(classifier, X, y)\n",
        "print(accuracy)\n",
        "# should give around 0.9545034107989363"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYYIADjZYPuP"
      },
      "source": [
        "##Function: Kernel Selection with Cross-Validation\n",
        "This function implements 4-fold cross-validation to evaluate the performance of different SVM kernels (Linear, Polynomial, RBF, and Sigmoid) for the binary classification problem. It splits the training data into 75% training and 25% validation in each fold, trains SVM models using Bag-of-Words features, and calculates the average accuracy for each kernel to determine the best-performing classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nq5AlMoUYPuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fa87dd-ca11-4b89-d8a4-6e4a765b98c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=4, random_state=1, shuffle=True)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "kf = sklearn.model_selection.KFold(n_splits=4, random_state=1, shuffle=True)\n",
        "kf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oJAjQyNKYPuT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a918ad2-0bd1-4256-8050-0b8c942e007e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'poly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "def best_model_selection(kf, X, y):\n",
        "    \"\"\"\n",
        "    Select the kernel giving best results using k-fold cross-validation.\n",
        "    Other parameters should be left default.\n",
        "    Input:\n",
        "    kf (sklearn.model_selection.KFold): kf object defined above\n",
        "    X (scipy.sparse.csr.csr_matrix): training data\n",
        "    y (array(int)): training labels\n",
        "    Return:\n",
        "    best_kernel (string)\n",
        "    \"\"\"\n",
        "    avg_accuracy = {}\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n",
        "        accuracy_kernel = []\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, y_train, X_test, y_test = X[train_index], y[train_index], X[test_index], y[test_index]\n",
        "            svm_classifier = learn_classifier(X_train, y_train, kernel)\n",
        "            model_accuracy = evaluate_classifier(svm_classifier, X_test, y_test)\n",
        "            accuracy_kernel.append(model_accuracy)\n",
        "        avg_accuracy[kernel] = np.mean(accuracy_kernel)\n",
        "\n",
        "    best_accuracy_kernel = max(avg_accuracy, key=avg_accuracy.get)\n",
        "    return best_accuracy_kernel\n",
        "best_kernel = best_model_selection(kf, X, y)\n",
        "best_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yho_UYX7YPuX"
      },
      "source": [
        "Wrapper function that will use model to classify unlabeled tweets from tweets_test.csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qth7DPekYPuY"
      },
      "outputs": [],
      "source": [
        "def classify_tweets(tfidf, classifier, unlabeled_tweets):\n",
        "    \"\"\" predicts class labels for raw tweet text\n",
        "    Inputs:\n",
        "        tfidf: sklearn.feature_extraction.text.TfidfVectorizer: the TfidfVectorizer object used on training data\n",
        "        classifier: sklearn.svm.SVC: classifier learned\n",
        "        unlabeled_tweets: pd.DataFrame: tweets read from tweets_test.csv\n",
        "    Outputs:\n",
        "        numpy.ndarray(int): dense binary vector of class labels for unlabeled tweets\n",
        "    \"\"\"\n",
        "\n",
        "    string_tweets = [\" \".join(process(tweet)) for tweet in unlabeled_tweets['text']]\n",
        "    X_test = tfidf.transform(string_tweets)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KKNMwVVgYPua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1706f2a-cfd0-4a53-f2d4-f36c6b15155d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "classifier = learn_classifier(X, y, best_kernel)\n",
        "unlabeled_tweets = pd.read_csv(\"/content/tweets_test.csv\", na_filter=False)\n",
        "y_pred = classify_tweets(tfidf, classifier, unlabeled_tweets)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dg5GJteAEs2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}